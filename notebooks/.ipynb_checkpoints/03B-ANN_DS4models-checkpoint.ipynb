{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6958cd5a-6a55-43a1-be4e-6e1a8ed0e482",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "Notebook that takes the splittet data from \"Split_data.ipynb\" and model the data using feed forward neural network on descriptorset including DS4\n",
    "Thus DS4, DS14 and DS24 and DS124 are being processed in this notebook\n",
    "Output: RMSE on the testsets exported for visualization in \"Figures.ipynb\"\n",
    "\n",
    "'''\n",
    "\n",
    "import sys, os\n",
    "sys.path.append('../src/insulin_pk/utils/') \n",
    "import pickle  \n",
    "import torch\n",
    "import optuna\n",
    "import random\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "# Import own modules:\n",
    "from utils import *\n",
    "# Supress optuna outputs and torch userwarnings\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Set seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "\n",
    "## Load data in folds and select only relevant descriptorset:\n",
    "DS1_folds = pickle.load(open('../data/processed/Data_folds.pkl','rb'))\n",
    "DS12_folds = pickle.load(open('../data/processed/Data_folds.pkl','rb'))\n",
    "DS2_folds = pickle.load(open('../data/processed/Data_folds.pkl','rb'))\n",
    "DS4_folds = pickle.load(open('../data/processed/Data_folds.pkl','rb'))\n",
    "\n",
    "\n",
    "for i in range(len(DS4_folds)):\n",
    "    for j in range(3):\n",
    "        DS12_folds[i][j] = contruct_descriptor_sets(DS12_folds[i][j],pd.Series(\"12\"))\n",
    "        DS1_folds[i][j] = contruct_descriptor_sets(DS1_folds[i][j],pd.Series(\"1\"))\n",
    "        DS2_folds[i][j] = contruct_descriptor_sets(DS2_folds[i][j],pd.Series(\"2\"))\n",
    "        DS4_folds[i][j] = contruct_descriptor_sets(DS4_folds[i][j],pd.Series(\"4\"))\n",
    "\n",
    "\n",
    "PK_names = ['CL[ml/min/kg]', 'T1/2[h]', 'MRT[h]']\n",
    "\n",
    "# Set training/validation epochs and number of bayesian optimization rounds\n",
    "EPOCH = 200\n",
    "N_TRIALS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cbacb76-ba28-43a7-bbed-7619901cff22",
   "metadata": {},
   "source": [
    "# DS124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9fd0dd67-02c0-4d26-9dbb-4a3622d300b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================BEGINNING FOLD 1 ==============\n",
      "=================BEGINNING FOLD 2 ==============\n",
      "=================BEGINNING FOLD 3 ==============\n",
      "=================BEGINNING FOLD 4 ==============\n",
      "=================BEGINNING FOLD 5 ==============\n"
     ]
    }
   ],
   "source": [
    "# Loop over test folds DS124\n",
    "CV_folds_test_vivo = {}\n",
    "for i in range(len(DS12_folds)): \n",
    "    print(\"=================BEGINNING FOLD {0} ==============\".format(i+1))\n",
    "    \n",
    "    \n",
    "    X_train, Y_train = DS12_folds[i][0],DS12_folds[i][3]  \n",
    "    X_val,Y_val = DS12_folds[i][1],DS12_folds[i][4]\n",
    "    X_test,Y_test = DS12_folds[i][2],DS12_folds[i][5]\n",
    "    scaler_Y = pickle.load(open('../data/processed/Scaler_Y_{0}.pkl'.format(i),'rb'))\n",
    "    \n",
    "    X_train_seq = DS4_folds[i][0].astype(np.float64)\n",
    "    X_train_seq.set_index(X_train.index,inplace = True)\n",
    "    X_val_seq = DS4_folds[i][1].astype(np.float64)\n",
    "    X_val_seq.set_index(X_val.index,inplace = True)\n",
    "    X_test_seq = DS4_folds[i][2].astype(np.float64)\n",
    "    X_test_seq.set_index(X_test.index,inplace = True)\n",
    "    \n",
    "    \n",
    "    dataset_train = Dataset_seq_embeddings(X_train,X_train_seq,Y_train)\n",
    "    dataset_val = Dataset_seq_embeddings(X_val,X_val_seq,Y_val)\n",
    "    dataset_test = Dataset_seq_embeddings(X_test,X_test_seq,Y_test)\n",
    "    \n",
    "\n",
    "    #study = optuna.create_study(direction=\"minimize\")\n",
    "    #study.optimize(lambda trial:objective_DS123(trial,Data_train = dataset_train ,Data_Val = dataset_val ,\n",
    "    #                                          Scaler_Y= scaler_Y,EPOCH=EPOCH,save_model=False,save_path = \"../models/VIVO_FFNN_DS124_fold{0}.pt\".format(i+1),\n",
    "    #                                          X_length = 100,\n",
    "    #                                          max_pool_kernel_size = 2),\n",
    "    #               \n",
    "    #               n_trials = N_TRIALS)\n",
    "    \n",
    "    \n",
    "    #trial_ = study.best_trial\n",
    "    #with open('../models/Optuna_DS124_fold{0}.pkl'.format(i),'wb') as f:pickle.dump(trial_.params,f )\n",
    "    #print(\"Best hyperparameters for fold {0} is saved\".format(i+1))\n",
    "    #print(f\" best parameters for this fold {trial_.params}\")\n",
    "    #best_params = pickle.load(open('../models/Optuna_DS124_fold{0}.pkl'.format(i),'rb'))\n",
    "    best_params = {'lr': 0.001,\n",
    "     'Batch_Size': 20,\n",
    "     'wd': 0.001,\n",
    "     'conv1_filters': 4,\n",
    "     'conv2_filters': 8,\n",
    "     'Kernel_size1': 3,\n",
    "     'dropout_FFNN': 0.4,\n",
    "     'dropout_CNN': 0.4,\n",
    "     'FC_after_CNN': 200,\n",
    "     'FC_After_DS12': 20,\n",
    "     'FC_Concatenation': 100}\n",
    "    # Build model using best hyperparameters:\n",
    "    model = model_DS123_build(best_params,input_dim_desc = DS12_folds[0][0].shape[1], X_length = 100,stride_CNN = 1,\n",
    "                 conv_dilation1 = 1,padding1 = 0, max_pool_kernel_size = 2)\n",
    "    #model.load_state_dict(torch.load(\"/home/kyei/Project1/Model files/VIVO_FFNN_DS123_fold{0}.pt\".format(i+1)))\n",
    "    \n",
    "    # Train model (again) on best hyperparameters for train/val diagnostic plots:\n",
    "    #print(\"Re-training best model\")\n",
    "    Vivo_train_results = train_and_validate_1CNN(Params = best_params,Model = model,Data_train = dataset_train ,Data_Val = dataset_val,\n",
    "                                            scaler_Y = scaler_Y,EPOCH = EPOCH,save_model = True,save_path = \"../models/VIVO_FFNN_DS124_fold{0}.pt\".format(i))\n",
    "    \n",
    "    # Make test set into dataloader:\n",
    "    test_loader = DataLoader(dataset = dataset_test,batch_size=X_test.shape[0],shuffle=False,drop_last = True)\n",
    "    \n",
    "    # Use best model to evaluate on unseen test data:\n",
    "    Vivo_test_results = test_1CNN(model,best_params, test_loader,scaler_Y = scaler_Y,save_path = \"../models/VIVO_FFNN_DS124_fold{0}.pt\".format(i) )\n",
    "    \n",
    "    CV_folds_test_vivo[i] = Vivo_test_results\n",
    "with open(\"../data/processed/ANN_outer_5_test_DS124.pkl\",'wb') as f:pickle.dump(CV_folds_test_vivo,f )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6da4c2-ec06-409f-b119-56ee2776baaf",
   "metadata": {},
   "source": [
    "# DS14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab98dbd-73d0-4c50-82d4-c565372315bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================BEGINNING FOLD 1 ==============\n",
      "Best hyperparameters for fold 1 is saved\n",
      " best parameters for this fold {'lr': 0.00023525181095294728, 'Batch_Size': 45, 'wd': 0.04814380925852638, 'conv1_filters': 19, 'conv2_filters': 26, 'Kernel_size1': 11, 'dropout_FFNN': 0.4184490525001554, 'dropout_CNN': 0.33845967520587356, 'FC_after_CNN': 196, 'FC_After_DS12': 18, 'FC_Concatenation': 96}\n",
      "=================BEGINNING FOLD 2 ==============\n",
      "Best hyperparameters for fold 2 is saved\n",
      " best parameters for this fold {'lr': 9.098347660091183e-05, 'Batch_Size': 40, 'wd': 0.015196095243663835, 'conv1_filters': 8, 'conv2_filters': 7, 'Kernel_size1': 12, 'dropout_FFNN': 0.33098655850678094, 'dropout_CNN': 0.5988902580519747, 'FC_after_CNN': 268, 'FC_After_DS12': 19, 'FC_Concatenation': 113}\n",
      "=================BEGINNING FOLD 3 ==============\n"
     ]
    }
   ],
   "source": [
    "# Loop over test folds DS14\n",
    "CV_folds_test_vivo = {}\n",
    "for i in range(len(DS1_folds)): \n",
    "    print(\"=================BEGINNING FOLD {0} ==============\".format(i+1))\n",
    "    \n",
    "    \n",
    "    X_train, Y_train = DS1_folds[i][0],DS1_folds[i][3]  \n",
    "    X_val,Y_val = DS1_folds[i][1],DS1_folds[i][4]\n",
    "    X_test,Y_test = DS1_folds[i][2],DS1_folds[i][5]\n",
    "    scaler_Y = pickle.load(open('../data/processed/Scaler_Y_{0}.pkl'.format(i),'rb'))\n",
    "    \n",
    "    X_train_seq = DS4_folds[i][0].astype(np.float64)\n",
    "    X_train_seq.set_index(X_train.index,inplace = True)\n",
    "    X_val_seq = DS4_folds[i][1].astype(np.float64)\n",
    "    X_val_seq.set_index(X_val.index,inplace = True)\n",
    "    X_test_seq = DS4_folds[i][2].astype(np.float64)\n",
    "    X_test_seq.set_index(X_test.index,inplace = True)\n",
    "    \n",
    "    \n",
    "    dataset_train = Dataset_seq_embeddings(X_train,X_train_seq,Y_train)\n",
    "    dataset_val = Dataset_seq_embeddings(X_val,X_val_seq,Y_val)\n",
    "    dataset_test = Dataset_seq_embeddings(X_test,X_test_seq,Y_test)\n",
    "    \n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(lambda trial:objective_DS123(trial,Data_train = dataset_train ,Data_Val = dataset_val ,\n",
    "                                              Scaler_Y= scaler_Y,EPOCH=EPOCH,save_model=False,save_path = \"../models/VIVO_FFNN_DS14_fold{0}.pt\".format(i+1),\n",
    "                                              X_length = 100,\n",
    "                                              max_pool_kernel_size = 2),\n",
    "                   n_trials = N_TRIALS)\n",
    "    \n",
    "    trial_ = study.best_trial\n",
    "    with open('../models/Optuna_DS14_fold{0}.pkl'.format(i),'wb') as f:pickle.dump(trial_.params,f )\n",
    "    print(\"Best hyperparameters for fold {0} is saved\".format(i+1))\n",
    "    print(f\" best parameters for this fold {trial_.params}\")\n",
    "    best_params = pickle.load(open('../models/Optuna_DS14_fold{0}.pkl'.format(i),'rb'))\n",
    "    # Build model using best hyperparameters:\n",
    "    model = model_DS123_build(best_params,input_dim_desc = DS1_folds[0][0].shape[1], X_length = 100,stride_CNN = 1,\n",
    "                 conv_dilation1 = 1,padding1 = 0, max_pool_kernel_size = 2)\n",
    "    #model.load_state_dict(torch.load(\"/home/kyei/Project1/Model files/VIVO_FFNN_DS123_fold{0}.pt\".format(i+1)))\n",
    "    \n",
    "    # Train model (again) on best hyperparameters for train/val diagnostic plots:\n",
    "    #print(\"Re-training best model\")\n",
    "    Vivo_train_results = train_and_validate_1CNN(Params = best_params,Model = model,Data_train = dataset_train ,Data_Val = dataset_val,\n",
    "                                            scaler_Y = scaler_Y,EPOCH = EPOCH,save_model = True,save_path = \"../models/VIVO_FFNN_DS14_fold{0}.pt\".format(i))\n",
    "    \n",
    "    # Make test set into dataloader:\n",
    "    test_loader = DataLoader(dataset = dataset_test,batch_size=X_test.shape[0],shuffle=False,drop_last = True)\n",
    "    \n",
    "    # Use best model to evaluate on unseen test data:\n",
    "    Vivo_test_results = test_1CNN(model,best_params, test_loader,scaler_Y = scaler_Y,save_path = \"../models/VIVO_FFNN_DS14_fold{0}.pt\".format(i) )\n",
    "    \n",
    "    CV_folds_test_vivo[i] = Vivo_test_results\n",
    "with open(\"../data/processed/ANN_outer_5_test_DS14.pkl\",'wb') as f:pickle.dump(CV_folds_test_vivo,f )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88af4803-df8f-442b-93c3-d4204847c071",
   "metadata": {},
   "source": [
    "# DS24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ae6ea-1fb5-4046-8da9-356f0eec575b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================BEGINNING FOLD 1 ==============\n",
      "Best hyperparameters for fold 1 is saved\n",
      " best parameters for this fold {'lr': 0.009986088975834978, 'Batch_Size': 39, 'wd': 0.018762155704265884, 'conv1_filters': 15, 'conv2_filters': 15, 'Kernel_size1': 28, 'dropout_FFNN': 0.3553557019661264, 'dropout_CNN': 0.3605855873078471, 'FC_after_CNN': 216, 'FC_After_DS12': 25, 'FC_Concatenation': 176}\n",
      "=================BEGINNING FOLD 2 ==============\n"
     ]
    }
   ],
   "source": [
    "# Loop over test folds DS24\n",
    "CV_folds_test_vivo = {}\n",
    "for i in range(len(DS12_folds)): \n",
    "    print(\"=================BEGINNING FOLD {0} ==============\".format(i+1))\n",
    "    \n",
    "    \n",
    "    X_train, Y_train = DS2_folds[i][0],DS2_folds[i][3]  \n",
    "    X_val,Y_val = DS2_folds[i][1],DS2_folds[i][4]\n",
    "    X_test,Y_test = DS2_folds[i][2],DS2_folds[i][5]\n",
    "    scaler_Y = pickle.load(open('../data/processed/Scaler_Y_{0}.pkl'.format(i),'rb'))\n",
    "    \n",
    "    X_train_seq = DS4_folds[i][0].astype(np.float64)\n",
    "    X_train_seq.set_index(X_train.index,inplace = True)\n",
    "    X_val_seq = DS4_folds[i][1].astype(np.float64)\n",
    "    X_val_seq.set_index(X_val.index,inplace = True)\n",
    "    X_test_seq = DS4_folds[i][2].astype(np.float64)\n",
    "    X_test_seq.set_index(X_test.index,inplace = True)\n",
    "    \n",
    "    \n",
    "    dataset_train = Dataset_seq_embeddings(X_train,X_train_seq,Y_train)\n",
    "    dataset_val = Dataset_seq_embeddings(X_val,X_val_seq,Y_val)\n",
    "    dataset_test = Dataset_seq_embeddings(X_test,X_test_seq,Y_test)\n",
    "    \n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(lambda trial:objective_DS123(trial,Data_train = dataset_train ,Data_Val = dataset_val ,\n",
    "                                              Scaler_Y= scaler_Y,EPOCH=EPOCH,save_model=False,save_path = \"../models/VIVO_FFNN_DS24_fold{0}.pt\".format(i+1),\n",
    "                                              X_length = 100,\n",
    "                                              max_pool_kernel_size = 2), \n",
    "                                              n_trials = N_TRIALS)\n",
    "    trial_ = study.best_trial\n",
    "    with open('../models/Optuna_DS24_fold{0}.pkl'.format(i),'wb') as f:pickle.dump(trial_.params,f )\n",
    "    print(\"Best hyperparameters for fold {0} is saved\".format(i+1))\n",
    "    print(f\" best parameters for this fold {trial_.params}\")\n",
    "    best_params = pickle.load(open('../models/Optuna_DS24_fold{0}.pkl'.format(i),'rb'))\n",
    "    # Build model using best hyperparameters:\n",
    "    model = model_DS123_build(best_params,input_dim_desc = DS2_folds[0][0].shape[1], X_length = 100,stride_CNN = 1,\n",
    "                 conv_dilation1 = 1,padding1 = 0, max_pool_kernel_size = 2)\n",
    "    #model.load_state_dict(torch.load(\"/home/kyei/Project1/Model files/VIVO_FFNN_DS123_fold{0}.pt\".format(i+1)))\n",
    "    \n",
    "    # Train model (again) on best hyperparameters for train/val diagnostic plots:\n",
    "    #print(\"Re-training best model\")\n",
    "    Vivo_train_results = train_and_validate_1CNN(Params = best_params,Model = model,Data_train = dataset_train ,Data_Val = dataset_val,\n",
    "                                            scaler_Y = scaler_Y,EPOCH = EPOCH,save_model = True,save_path = \"../models/VIVO_FFNN_DS24_fold{0}.pt\".format(i))\n",
    "    \n",
    "    # Make test set into dataloader:\n",
    "    test_loader = DataLoader(dataset = dataset_test,batch_size=X_test.shape[0],shuffle=False,drop_last = True)\n",
    "    \n",
    "    # Use best model to evaluate on unseen test data:\n",
    "    Vivo_test_results = test_1CNN(model,best_params, test_loader,scaler_Y = scaler_Y,save_path = \"../models/VIVO_FFNN_DS24_fold{0}.pt\".format(i) )\n",
    "    \n",
    "    CV_folds_test_vivo[i] = Vivo_test_results\n",
    "with open(\"../data/processed/ANN_outer_5_test_DS24.pkl\",'wb') as f:pickle.dump(CV_folds_test_vivo,f )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27af7b3-ac97-4a09-aab4-44baf4c0fddb",
   "metadata": {},
   "source": [
    "# DS4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1613e28d-4aa3-4d88-b71f-a02fa8eb6eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over test folds DS4\n",
    "CV_folds_test_vivo = {}\n",
    "for i in range(len(DS12_folds)): \n",
    "    print(\"=================BEGINNING FOLD {0} ==============\".format(i+1))\n",
    "    \n",
    "    \n",
    "    X_train, Y_train = DS2_folds[i][0],DS2_folds[i][3]  \n",
    "    X_val,Y_val = DS2_folds[i][1],DS2_folds[i][4]\n",
    "    X_test,Y_test = DS2_folds[i][2],DS2_folds[i][5]\n",
    "    \n",
    "    ## Set all numeric entries to 0 (as we only have sequential data in this case). Ineffective but valid if we want to keep using the current framework and functions:\n",
    "    X_train = pd.DataFrame(0.0, index=X_train.index, columns=X_train.columns)\n",
    "    X_val = pd.DataFrame(0.0, index=X_val.index, columns=X_val.columns)\n",
    "    X_test = pd.DataFrame(0.0, index=X_test.index, columns=X_test.columns)\n",
    "    \n",
    "    \n",
    "    scaler_Y = pickle.load(open('../data/processed/Scaler_Y_{0}.pkl'.format(i),'rb'))\n",
    "    \n",
    "    X_train_seq = DS4_folds[i][0].astype(np.float64)\n",
    "    X_train_seq.set_index(X_train.index,inplace = True)\n",
    "    X_val_seq = DS4_folds[i][1].astype(np.float64)\n",
    "    X_val_seq.set_index(X_val.index,inplace = True)\n",
    "    X_test_seq = DS4_folds[i][2].astype(np.float64)\n",
    "    X_test_seq.set_index(X_test.index,inplace = True)\n",
    "    \n",
    "    \n",
    "    dataset_train = Dataset_seq_embeddings(X_train,X_train_seq,Y_train)\n",
    "    dataset_val = Dataset_seq_embeddings(X_val,X_val_seq,Y_val)\n",
    "    dataset_test = Dataset_seq_embeddings(X_test,X_test_seq,Y_test)\n",
    "    \n",
    "\n",
    "    study = optuna.create_study(direction=\"minimize\")\n",
    "    study.optimize(lambda trial:objective_DS123(trial,Data_train = dataset_train ,Data_Val = dataset_val ,\n",
    "                                              Scaler_Y= scaler_Y,EPOCH=EPOCH,save_model=False,save_path = \"../models/VIVO_FFNN_DS4_fold{0}.pt\".format(i+1),\n",
    "                                              X_length = 100,\n",
    "                                              max_pool_kernel_size = 2),\n",
    "                                              n_trials = N_TRIALS)\n",
    "    trial_ = study.best_trial\n",
    "    with open('../models/Optuna_DS4_fold{0}.pkl'.format(i),'wb') as f:pickle.dump(trial_.params,f )\n",
    "    print(\"Best hyperparameters for fold {0} is saved\".format(i+1))\n",
    "    print(f\" best parameters for this fold {trial_.params}\")\n",
    "    best_params = pickle.load(open('../models/Optuna_DS4_fold{0}.pkl'.format(i),'rb'))\n",
    "    # Build model using best hyperparameters:\n",
    "    model = model_DS123_build(best_params,input_dim_desc = DS2_folds[0][0].shape[1], X_length = 100,stride_CNN = 1,\n",
    "                 conv_dilation1 = 1,padding1 = 0, max_pool_kernel_size = 2)\n",
    "    #model.load_state_dict(torch.load(\"/home/kyei/Project1/Model files/VIVO_FFNN_DS123_fold{0}.pt\".format(i+1)))\n",
    "    \n",
    "    # Train model (again) on best hyperparameters for train/val diagnostic plots:\n",
    "    #print(\"Re-training best model\")\n",
    "    Vivo_train_results = train_and_validate_1CNN(Params = best_params,Model = model,Data_train = dataset_train ,Data_Val = dataset_val,\n",
    "                                            scaler_Y = scaler_Y,EPOCH = EPOCH,save_model = True,save_path = \"../models/VIVO_FFNN_DS4_fold{0}.pt\".format(i))\n",
    "    \n",
    "    # Make test set into dataloader:\n",
    "    test_loader = DataLoader(dataset = dataset_test,batch_size=X_test.shape[0],shuffle=False,drop_last = True)\n",
    "    \n",
    "    # Use best model to evaluate on unseen test data:\n",
    "    Vivo_test_results = test_1CNN(model,best_params, test_loader,scaler_Y = scaler_Y,save_path = \"../models/VIVO_FFNN_DS4_fold{0}.pt\".format(i) )\n",
    "    \n",
    "    CV_folds_test_vivo[i] = Vivo_test_results\n",
    "with open(\"../data/processed/ANN_outer_5_test_DS4.pkl\",'wb') as f:pickle.dump(CV_folds_test_vivo,f )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
